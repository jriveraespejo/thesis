\chapter{Introduction}

\section{Preliminar considerations}

Local independence is one of the key assumptions of Item Response Theory (IRT) models, and it is comprised of two parts: (i) local item independence and (ii) local individual independence \cite{Baker_2001, Hambleton_et_al_1991a}. In the former case, the assumption entails that the individual's response to an item does not affect the probability of endorsing another item, after conditioning on the individual's ability. While in the case of the latter, the assumption considers that an individual's response to an item, is independent of another person's response to that same item \cite{Reckase_2009}. 

The literature has shown that IRT models are not robust to the violation of local independence. The transgression of the assumption affects model parameter estimates, inflates measurement reliabilities and test information, and underestimates standard errors (see \citet{Yen_1984, Chen_et_al_1997}, and  \citet{Jiao_et_al_2012}). 

However, item response data arising from educational assessments often display several types of dependencies, violating the local item and/or individual independence, e.g. testlets, where items are constructed around a common stimulus \cite{Wainer_et_al_2007}; the measurement of multiple latent traits within individuals \cite{Reckase_2009}; cluster effects, where correlation among individuals results from the sampling and measurement mechanism used to gather the data \cite{Raudenbush_et_al_2002}; among others. A good motivating example, that will permeate this research, is the reading comprehension sub-test, from the Peruvian public teaching career national assessment. The test is designed to measure three hierarchically nested sub-dimensions of reading comprehension: literal, inferential, and reflective abilities. Furthermore, the items are bundled together in testlets related to a common text or passage. Finally, multiple cluster effects are present, e.g. at the region, and district level, just to mention a few.

Recent studies have proposed IRT Dual Dependency Models (DDM) to deal with the testlets and individual clustering dependencies observed in the data \cite{Fujimoto_2020, Fujimoto_2018a, Fujimoto_2018b, Jiao_et_al_2012, Flores_2012, Fox_2010, Reckase_2009, Bradlow_1999}. The majority of these representations have been developed under the Bayesian framework, and they are similar in parametrization to multilevel models. On the other hand, an almost independent line of research, the Generalized Linear Latent and Mixed Models (GLLAMM) \cite{Rabe_et_al_2004a, Rabe_et_al_2004b, Skrondal_et_al_2004a, Rabe_et_al_2012}, have extended the capabilities of hierarchical models on the estimation of multiple latent traits at different hierarchical levels. These developments have been motivated mostly under the frequentist framework, and they are similar in parametrization to a Multilevel Structural Equation Model (MSEM).

While the initial sense is that both developments are independent of each other, following their literature, one can easily notice that they share more than a resemblance. Both follow a multilevel/hierarchical multidimensional approach to account for the clustering of persons within samples and/or items within bundles (DDM), or the latent structures within the individuals (GLLAMM). However, it is important to point out that in some cases the model parametrization between the two developments differs in a way, that some of them appear to be useful only under their specific contexts. Fortunately, their integration under the Bayesian framework is not only trivial, but it can be motivated under either type of model.

The benefits of the integration revolve around two facts: (i) educational data often presents all of the aforementioned dependencies and more, as in the motivating example; and (ii) as it was hinted in the second paragraph, to reach appropriate conclusions from the parameter estimates, IRT models need to account for all of these dependencies. The latter is particularly important as, more often than not, a researcher is interested in producing inferences at the structural level of the model, i.e. how a different set of manifest variables explain the variability in the latent variables, or how the latent variables explain other manifest or latent variables, at different levels. As an example, one might be interested in finding evidence if the latent ``abilities" of the teachers are explained by their initial educational conditions, i.e. if they were educated in an institute, university, or both. The main purpose of this would be to identify the type of teacher that might benefit more from the in-service training\footnote{Intervention designed with the purpose of potentiating specific abilities in teachers that are currently part of the public teaching career.}, offered by the national educational authorities, making the intervention cost-effective.

From the previous description, one can infer that the proposed IRT representation would be complex and highly dimensional. Moreover, as educational assessments are usually scored in a binary way (the individual either endorse or not the item), and because not all individuals are assessed by all items, the model will be estimated with sparse data. From the modeling perspective, neither of the previous points presents a challenge for the bayesian framework. However, it has long been recognized that complex parametrizations, that allow this powerful modeling schemes, introduce pathologies that make Markov Chain Monte Carlo methods (MCMC)  face performance challenges \cite{Gelfand_et_al_1995, Gelfand_et_al_1996, Papaspiliopoulos_et_al_2003, Papaspiliopoulos_et_al_2007, Betancourt_et_al_2013}, e.g. not achieving stationarity and/or not making a proper exploration of the posterior sampling space. This is highly relevant because, in order to make inferences about the posterior distribution of the parameters, the chains need to achieve three requirements, highly related to the performance of the method: stationarity, convergence, and good mixing \cite{McElreath_2020}.

Throughout the bayesian IRT literature, one often finds that four solutions are offered to ensure the fulfillment of the previous requirements, and they can be classified into two broad groups: (i) solutions that involve changing the settings of the MCMC method, and (ii) solutions that involve readjusting the Bayesian model. 

In the first category, we find two proposals: (a) increasing the number of iterations per chain, with large burn-in and thinning processes, and (b) designing model-specific MCMC algorithms. The easiest to implement and more prevalent in the literature is the former, e.g. \citet{Fujimoto_2018a} used chains with $60,000$ iterations, where $15,000$ were discarded and the remaining were thinned in jumps of $3$; while \citet{Fujimoto_2018b} used $225,000$ iterations, with burn-in of $30,000$ and thinning with jumps of $15$. Among the drawbacks of this solution are the large computational times; the user involvement in deciding the specific setting for the process, which could be different for different parameters in the same model; and finally, the lack of confidence that larger chain iterations actually produce a proper posterior investigation. On the other hand, several authors have developed high-tech MCMC algorithms that aim to optimize their performance within a particular class of models \cite{Papaspiliopoulos_et_al_2007}. In these cases, the developers re-evaluate not only the use of the programming language, with the purpose of speeding and improving performance (e.g. \citet{Fujimoto_2018a}); but also the inclusion of ad-hoc model assumptions, like prior conjugancy\footnote{when the prior and posterior distribution belong to the same parametric family.} for specific parameters or highly regularizing priors (see next paragraph), to mention a few. Examples of this solutions are in staple software developments like Mplus \cite{Muthen_et_al_2011} or Stata \cite{Rabe_et_al_2004c}. It is clear from the previous that this solution is not accessible to all researchers, either because of the lack of programming skills, or the restrictive cost of access involved in acquiring the software. But more importantly, these solutions are not always applicable to a wider framework of similar models \cite{Papaspiliopoulos_et_al_2007}.

In the second category, we also find two proposed solutions: (a) re-write the model in an alternative parametrization, and (b) encode prior information through the prior distributions, i.e. use regularizing priors. On both solutions, the purpose is to ensure the identification of the parameters within the model, which helps to stabilize the MCMC procedure \cite{Gelman_et_al_2014}. An example of the former is \citet{Fujimoto_2018a}, who decomposed the items' discriminatory parameters into overall and specific item discriminations. For the latter, \citet{Fujimoto_2020} used informative priors also for the items' discrimination parameters.

More often than not, researchers use two or more of the aforementioned solutions to reach an acceptable performance in the chains. However, as point out by \citet{Betancourt_et_al_2013}, even the most simple hierarchical models present formidable pathologies, that no simple correction can be performed to visit the posterior distribution properly. This is true no matter the rotation/rescaling of the parameter, or the amount of data. In this context, several authors \cite{Gelfand_et_al_1995, Gelfand_et_al_1996, Papaspiliopoulos_et_al_2003, Papaspiliopoulos_et_al_2007, Betancourt_et_al_2013} showed that prior information can be included in the model, not only through the prior distributions, but also by encoding it in the model itself, changing the posterior sampling geometries by removing the dependence of the parameters on other sampled parameters, therefore favoring the performance of MCMC chains.

Given all of the above, the present research will focus on showing how easy it is to account for all of the dependencies that educational data often display, under the GLLAMM framework. Furthermore,  given that only the literature related to gaussian hierarchical models have shown the benefits of changing the posterior sampling geometries, through the use of the non-centered parameterization \cite{Gelfand_et_al_1995, Gelfand_et_al_1996, Papaspiliopoulos_et_al_2003, Papaspiliopoulos_et_al_2007, Betancourt_et_al_2013}, it seems sensible to provide a similar assessment for nonlinear hierarchical models, and in particular, the ones with latent stochastic processes like IRT \cite{Papaspiliopoulos_et_al_2007}. Finally, the research will apply the newfound knowledge to data coming from a large Teacher's standardized educational assessments from Peru.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Objectives}

As mentioned in the previous section, the present research has a three-fold purpose:

\begin{enumerate}
	\item Motivate the Bayesian GLLAMM for binary outcomes \cite{Rabe_et_al_2004a, Rabe_et_al_2004b, Skrondal_et_al_2004a, Rabe_et_al_2012}. The representation will emphasize the modeling of multiple hierarchical latent structures and testlets. This, in turn, will effectively blur the division between the GLLAMM framework and IRT models.
	
	\item Empirically evaluate the benefits of changing the posterior sampling geometry, in the context of the Bayesian GLLAMM for binary outcomes. The emphasis here will be on comparing the centered and non-centered parametrizations \cite{Gelfand_et_al_1995, Gelfand_et_al_1996} in terms of performance of the chains, the parameter's recovery capacity, the retrodictive accuracy, and the ability of the model to produce appropriate inferences.
	
	\item Apply the model and its parametrization to a real data setting. Here the emphasis will be to assess the conclusions arrived from the application of the model, and what they could imply for the educational authorities.
\end{enumerate}

\noindent Given the aforementioned goals, the researcher believes the master's thesis contributes to the literature in two aspects: 

\begin{enumerate}
	\item In a theoretical and methodological sense, as the research is focused on describing a model that effectively controls for the multiple dependencies usually observed in educational data sets; and 
	
	\item In a more practical sense, as the study will provide empirical evidence if changing the sampling posterior geometries could (could not) benefit the performance of MCMC methods and therefore the inferences, under IRT models.
\end{enumerate}

\noindent Finally, it is important to mention, that the computational implementation of the method will be developed in \texttt{Stan} \cite{Stan2020} and \texttt{R} \cite{R2015, RStan2020}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Organization}

Chapter \ref{chap:framework} will motivate the GLLAMM for dichotomous outcomes, and define its components. Chapter \ref{chap:estimation} will describe the bayesian framework, its benefits and shortcomings. Furthermore, it will outline the evidence behind the change in posterior sampling geometries, and the computational implementation of the model. Chapter \ref{chap:simulation} will show the results of an empirical simulation study designed to assess the benefits of the re-parametrization, proposed in the previous chapter. Chapter \ref{chap:application} will describe the instruments, the data collection process, and scales under analysis, for a large standardized educational assessment. In addition, the chapter will show the conclusions achieved by the application of the model in the said data. Finally, Chapter \ref{cap:conclusions}, will discuss the conclusion for the research, and it will outline the path of future research topics that can be derived from the present effort.
