\chapter{The Generalized Linear Latent and Mixed Model} \label{chap:framework}

The Generalized Linear Latent and Mixed Model (GLLAMM) is a framework that unifies a wide range of latent variable models. Developed by \citet{Rabe_et_al_2004a, Rabe_et_al_2004b, Rabe_et_al_2004c, Skrondal_et_al_2004a, Rabe_et_al_2012}, the method was motivated by the need of a multilevel Structural Equation Model (SEM) that accommodates for unbalanced data, noncontinuous responses and the use of cross-level effects among latent variables. 

This chapter presents the definition, characteristics, assumptions and properties of such framework.


\section{Definition} \label{sect:definition}
Following \citet{Rabe_et_al_2004a, Rabe_et_al_2012}, we depart from the traditional multivariate framework for formulating factor and structural models, i.e. a "wide" data format, and adopt a univariate approach, i.e. "long" or vectorized format. In that sense, for each unit, the response variables are "stacked" in a single response vector, with different variables distinguished from each other, by a design matrix. With this structure, we proceed to outline the three parts of the framework: 
\begin{enumerate}
	\item The response model, 
	\item The structural latent variable model, and 
	\item The distribution of the latent variables. 
\end{enumerate}
For a detailed description of some of the special cases of multilevel SEM, that can be derived with this framework, refer to Appendix \ref{appA:additional}.


\subsection{Response model} \label{s_sect:response}
As outlined by the authors, conditional on the latent variables, the response model is a Generalized Linear Model (GLM) defined by a systematic and a distributional part. For the systematic part, a linear predictor and a link function are selected, in accordance to the characteristics of the manifest variables. On the other hand, for the distributional part, a distribution from the exponential family is selected.

In the following sections, we proceed to describe the linear predictor, the link function and the distributions accommodated by the framework.


\subsubsection{Linear predictor} \label{ss_sect:linear_predictor}
For a model with $L$ levels and $M_{l}$ latent variables at $l>1$ levels, the linear predictor takes the following form:
\begin{equation} \label{eq:linear_predictor}
	v = \mathbf{X} \pmb{\beta} + \sum_{l=2}^{L} \sum_{m=1}^{M_{(l)}} \eta_{m}^{(l)} \mathbf{Z}_{m}^{(l)} \pmb{\lambda}_{m}^{(l)}
\end{equation}

\noindent where $\mathbf{X}$ is a design matrix that maps the parameter vector $\pmb{\beta}$ to the linear predictor, $\eta_{m}^{(l)}$ the $m$th latent variable at level $l$ ($m=1, \dots, M_{(l)}$ and $l=1, \dots, L$), and $\mathbf{Z}_{m}^{(l)}$ a design matrix that maps the vector of loadings $\pmb{\lambda}_{m}^{(l)}$ to the $m$th latent variable at level $l$.

Note that wo do not use subscripts for the units of observation at different levels. This decision was made with the purpose of avoiding the use of mathematical definitions with large number of subscripts. However, a careful reader should consider that equation (\ref{eq:linear_predictor}) rest on the assumption that each unit is identified at their appropriate level. For special cases of multilevel SEM, and their use of subscripts, refer to Appendix \ref{appA:additional}.

\subsubsection{Links and Distributions} \label{ss_sect:link_dist}
As in the GLM framework, the model "links" the expectation of the conditional response, to the linear predictor, through a inverse-link function $h(\cdot)$, in the following form: 
\begin{equation} \label{eq:response_function}
	\mu = E[y | \mathbf{X}, \mathbf{Z}, \pmb{\eta}] = h(v)
\end{equation}

\noindent where equation (\ref{eq:response_function}) can be re-written in terms of the link function $g(\cdot) = h^{-1}(\cdot)$:
\begin{equation} \label{eq:link_function}
	g(\mu) = g(E[y | \mathbf{X}, \mathbf{Z}, \pmb{\eta}]) = v
\end{equation}

\noindent with $\pmb{\eta}=\left[\eta^{(2)T}, \dots, \eta^{(L)T}\right]^{T}$ and $\mathbf{Z}=\left[\mathbf{Z}^{(2)T}, \dots, \mathbf{Z}^{(L)T}\right]^{T}$, as the "stacked" vector of latent variables, and the "stacked" design matrices of explanatory variables, for all $L$ levels, respectively. Additionally, $\pmb{\eta}^{(l)}=\left[\eta_{1}^{(l)}, \dots, \eta_{M_{(l)}}^{(l)}\right]^{T}$ and $\mathbf{Z}^{(l)}=\left[\mathbf{Z}_{1}^{(l)T}, \dots, \mathbf{Z}_{M_{(l)}}^{(l)T}\right]^{T}$, denotes the vector of latent variables, and the "stacked" design matrix of explanatory variables, at level $l$, respectively.

Finally, the response model specification is complete when we select an appropriate distribution from the family of exponential distributions. The types of responses that can be accommodated by the framework are the following:

\begin{enumerate}
	
	\item \textbf{Continuous:} \\
	It results form selecting an identity link function for the scaled mean response,
	\begin{equation} \label{eq:link_cont}
		\begin{split}
		\mu^{*} &= E[y^{*} | \mathbf{X}, \mathbf{Z}, \pmb{\eta}] \\ 
		&= v
		\end{split}
	\end{equation}
	where $\mu^{*} = \mu \sigma^{-1}$, $y^{*} = y \sigma^{-1}$, and $\sigma$ denotes the standard deviation of the errors.
	
	On the other hand, the distributional part is defined by a Standard Normal distribution $\phi(x)=(2 \pi)^{-1/2} exp(-x^{2}/2)$,
	\begin{equation} \label{eq:dist_cont}
		\begin{split}
		f(y^{*}| \mathbf{X}, \mathbf{Z}, \pmb{\eta}) &= \phi(\mu^{*}) \sigma^{-1} \\
		&= \phi(v) \sigma^{-1}
		\end{split}
	\end{equation}
	Notice that the same parametrization can be achieved considering $y^{*} = v + \epsilon^{*}$, and $\epsilon^{*} \sim N(0, 1)$.
	Additionally, the decision to standardize the response variables has been made with the purpose of making the estimation process easier, as such distribution is free of unknown parameters.
	
	
	
	\item \textbf{Dichotomous:} \\
	It results from selecting an appropriate inverse-link function for the expected value of the manifest variable, which describe the probability of endorsing one of the two available categories,
	\begin{equation} \label{eq:link_dich}
		\begin{split}
		\mu &= E[y=1 | \mathbf{X}, \mathbf{Z}, \pmb{\eta}] \\ 
		&= P[y=1 | \mathbf{X}, \mathbf{Z}, \pmb{\eta}] \\
		&= \pi \\
		&= h(\kappa - v)
		\end{split}	
	\end{equation}
	where $\kappa$ is the decision threshold, and $h(\cdot)$ can be defined in three ways:	
	\begin{equation} \label{eq:response_dich1}
		h(x) = 
		\begin{cases}
			exp(x)[1 + exp(x)]^{-1} \\
			\Phi(x) \quad \text{No closed form.} \\
			exp(-exp(x))
		\end{cases}
	\end{equation}
	which corresponds to the logistic, standard normal $\Phi(x)$, and Gumbel (extreme value type I) \textit{cumulative distributions}, respectively. In terms of link functions, the distributions corresponds to the well known logit, probit and complementary log-log link functions, respectively. 
	
	Alternatively, the same parametrization can be achieved using the concept of an underlying latent variable in the form $y^{*} = v + \epsilon^{*}$, where $y = 1$ if $y^{*} \ge \kappa$, and $\epsilon^{*}$ can have a distribution as the ones defined in equation (\ref{eq:response_dich1}). It is important to mention that under this parametrization, the threshold parameters $\kappa$ and the $\pmb{\beta}$ {\color{red} are confounded as they serve similar purposes, so only one would be estimated}.
	
	Finally, the distributional part is defined by a Binomial distribution,
	\begin{equation} \label{eq:dist_dich}
		\begin{split}
		f[y=1 | \mathbf{X}, \mathbf{Z}, \pmb{\eta}] &= \binom{n}{k} \mu^{k} (1-\mu)^{n-k} \\
		&= \binom{n}{k} \pi^{k} (1-\pi)^{n-k}
		\end{split}
	\end{equation}

	where $k$ denotes the number of successes in $n$ independent Bernoulli trials.
	
	
			
	\item \textbf{Polytomous:} \\	
	It results from selecting a generalized logistic inverse-link function \cite{Bock_1972} for the expected value of the response, which in this case, describe the probability of endorsing one of the $S$ unordered available categories,
	\begin{equation} \label{eq:link_poly}
		\begin{split}
		\mu_{s} &= E[y=y_{s} | \mathbf{X}, \mathbf{Z}, \pmb{\eta}] \\
		&= P[y=y_{s} | \mathbf{X}, \mathbf{Z}, \pmb{\eta}] \\
		& = \pi_{s} \\
		&= h(v_{s})
		\end{split}
	\end{equation}	
	where $v_{s}$ is the linear predictor for category $s$ ($s=1, \dots, S$), and $h(\cdot)$ is defined as:
	\begin{equation} \label{eq:response_poly}
		h(x) = exp(x)\left[\sum_{s=1}^{S} exp(x)\right]^{-1}
	\end{equation}
	It is important to note that, as in the dichotomous case, the same parametrization can be achieved using the concept of underlying continuous responses in the form $y_{s}^{*} = v_{s} + \epsilon_{s}$, where $y = s$ if $y_{s}^{*} > y_{k}^{*}$ $\forall s, s \neq k$, $\epsilon_{s}$ have a Gumbel (extreme value type I) distribution, as the one defined in equation (\ref{eq:response_dich1}), and $y_{s}$ denotes the random utility for the $s$ category.
	
	
	Finally, the distributional part is defined by a Multinomial distribution,
	\begin{equation} \label{eq:dist_poly}
		\begin{split}
		f[y=\{y_{1}, \cdots, y_{S}\} | \mathbf{X}, \mathbf{Z}, \pmb{\eta}] &= \frac{n!}{y_{1}! \cdots y_{S}!} \prod_{s=1}^{S} \mu_{s}^{y_{s}} \\
		&= \frac{n!}{y_{1}! \cdots y_{S}!} \prod_{s=1}^{S} \pi_{s}^{y_{s}}
		\end{split}
	\end{equation}
	
	where $y_{s}$ denotes the number of "successes" in category $s$.

	
	
	\item \textbf{Ordinal and discrete time duration:} \\
	For the ordinal case, the linear predictor is "linked" to the probability of endorsing category $s$, against all previous categories, in the following form:
	\begin{equation} \label{eq:link_ord1}
		\begin{split}
			\mu_{s} &= E[y = y_{s} | \mathbf{X}, \mathbf{Z}, \pmb{\eta}] \\
			&= P[y \leq y_{s} | \mathbf{X}, \mathbf{Z}, \pmb{\eta}] - P[y \leq y_{s-1} | \mathbf{X}, \mathbf{Z}, \pmb{\eta}] \\
			&= h(\kappa_{s} - v_{s}) - h(\kappa_{s-1} - v_{s-1})
		\end{split}
	\end{equation}
	where $\kappa_{s}$ denotes the thresholds for category $s$. For discrete time duration, the linear predictor is "linked" to the probability of survival, in the $s$th time interval, as follows:
	\begin{equation} \label{eq:link_ord2}
		\begin{split}
			\mu_{s} &= E[t_{s-1} \leq T \le t_{s} | \mathbf{X}, \mathbf{Z}, \pmb{\eta}] \\
			&= P[T \leq t_{s} | \mathbf{X}, \mathbf{Z}, \pmb{\eta}] - P[T \leq t_{s-1} | \mathbf{X}, \mathbf{Z}, \pmb{\eta}] \\
			&= h(v_{s} + t_{s}) - h(v_{s-1} + t_{s-1})
		\end{split}
	\end{equation}
	where $T$ is the unobserved continuous time, and $t_{s}$ its observed discrete realization. Additionally, for both type of responses, $h(\cdot)$ can be defined as the logistic, standard normal, and Gumbel (extreme value type I) \textit{cumulative distributions}, as in equation (\ref{eq:response_dich1}).
	
	Similar to the dichotomous and polytomous case, the same parametrization can be achieved using the concept of underlying latent variables with $y_{s}^{*} = v_{s} + \epsilon_{s}$, where $y = s$ if $\kappa_{s-1} < y_{s}^{*} \le \kappa_{s}$, $\kappa_{0}=-\infty$, $\kappa_{1}=0$, $\kappa_{S}=+\infty$, $\epsilon_{s}$ has one of the distributions in equation (\ref{eq:response_dich1}), and $y_{s}$ denotes the random utility for the $s$ category.
	
	It is important to note, for discrete time duration responses, the logit link corresponds to a \textit{Proportional-Odds model}, while the complementary log-log link to a \textit{Discrete Time Hazards model} \cite{Rabe_et_al_2001}. Other models for ordinal responses, such as the \textit{Baseline Category Logit} or the \textit{Adjacent Category Logit} models can be specified as special cases of the generalized logistic response function, defined in equation (\ref{eq:response_poly}). 
	
	Finally, the distributional part is defined by a Multinomial distribution, as the one defined in equation (\ref{eq:dist_poly}).
	
	
	
	\item \textbf{Counts and continuous time duration:} \\
	It results from selecting an exponential inverse-link function (log link) for the expected value of the response,
	\begin{equation} \label{eq:link_count}
		\begin{split}
		\mu &= E[y | \mathbf{X}, \mathbf{Z}, \pmb{\eta}] \\
		&= \lambda \\
		&= exp(v)
		\end{split}
	\end{equation}
	and a Poisson conditional distribution for the counts,
	\begin{equation} \label{eq:dist_count}
		\begin{split}
		f[y| \mathbf{X}, \mathbf{Z}, \pmb{\eta}] &= exp(-\mu) \mu^{y} (y!)^{-1} \\
		&= exp(-\lambda) \lambda^{y} (y!)^{-1}
		\end{split}
	\end{equation}
	It is important to mention that unlike the models for dichotomous, polytomous and ordinal responses, model for counts cannot be written under the random utility framework.
	
	
	
	\item \textbf{Rankings and pairwise comparisons:} \\
	Following \citet{Skrondal_et_al_2003a}, the parametrization for polytomous responses can serve as the building block for the conditional distribution of rankings. Selecting a "exploded logit" inverse-link function \cite{Chapaaan_et_al_1982} for the expected value of the response, which describes the probability of the full rankings of category $s$,
	
	{\color{red} (work in progress) \\
	\begin{equation} \label{eq:link_rank}
		\begin{split}
			\mu_{s} &= P[\mathbf{R}_{s}= \{ r_{s}^{1}, \dots r_{s}^{1}\} | \mathbf{X}, \mathbf{Z}, \pmb{\eta}] \\
			& = \pi_{s} \\
			&= h(v_{s})
		\end{split}
	\end{equation}	
	where $v_{s}$ is the linear predictor for category $s$ ($s=1, \dots, S$), and $h(\cdot)$ is defined as:
	\begin{equation} \label{eq:response_rank}
		h(x) = \prod_{s=1}^{S} exp(x^{s})\left[\sum_{s=1}^{S} exp(x^{s})\right]^{-1}
	\end{equation}

	Again, as in specific previous cases, the same parametrization can be achieved using the concept of underlying latent variables.
	
	Finally, the distributional part is defined by a Multinomial distribution,
	\begin{equation} \label{eq:dist_rank}
		\begin{split}
			f[y=\{y_{1}, \cdots, y_{S}\} | \mathbf{X}, \mathbf{Z}, \pmb{\eta}] &= \frac{n!}{y_{1}! \cdots y_{S}!} \prod_{s=1}^{S} \mu_{s}^{y_{s}} \\
			&= \frac{n!}{y_{1}! \cdots y_{S}!} \prod_{s=1}^{S} \pi_{s}^{y_{s}}
		\end{split}
	\end{equation}
	
	where $y_{s}$ denotes the number of "success cases" in category $s$.
	}


		
	\item \textbf{Mixtures:} \\
	Given the previous definitions, the framework easily lends itself to model five additional settings:
	
	\begin{enumerate}
		\item \textbf{Different links and distributions for different latent variables}. This can be easily achieved by setting different links and distributions for each of the $M_{2}$ latent variables located at level $2$.
		
		
		\item \textbf{Left- or right-censored continuous responses}. Common in selection models (e.g. \citet{Hekman_1979}), they can be achieved by specifying an identity link and Normal distribution for the uncensored scaled responses, as in equations (\ref{eq:link_cont}) and (\ref{eq:dist_cont}); and a scaled probit link and Binomial distribution otherwise, as in equations (\ref{eq:response_dich1}) and (\ref{eq:dist_dich}).
		
		
		\item \textbf{zero-inflated count responses}. where a log link and a Poisson distribution is set for the counts, as in equations (\ref{eq:link_count}) and (\ref{eq:dist_count}); and a logit link and Binomial distribution is specified to model the zero center of mass, as in equations (\ref{eq:link_dich}) and (\ref{eq:dist_dich}).
		
		
		\item \textbf{Measurement error in covariates}. this setting occurs when standard models use variables, with measurement error, as covariates, e.g. a logistic regression with a continuous covariate that presents measurement error. For more details on this type of setting see \citet{Rabe_et_al_2003a, Rabe_et_al_2003b}, and \citet{Skrondal_et_al_2003b}.
		
		
		\item \textbf{Composite links}. Useful for specifying proportional odds models for right-censored responses, for handling missing categorical covariates and many other model types. For more details on this type of settings see \citet{Skrondal_et_al_2004b}.
	\end{enumerate}

\end{enumerate}





\subsubsection{Heteroscedasticity and over-dispersion in the response} \label{ss_sect:het}

Much like the Generalized Linear Mixed Model framework (GLMM), the GLLAMM allows to model heteroscedasticity, and over- or under-dispersion by adding random effects to the linear predictor, at level $1$. The types of responses, in which such characteristics can be modeled, are the following:

\begin{enumerate}
	\item \textbf{Continuous:} \\
	We model \textbf{heteroscedasticity} in the following form:
	\begin{equation} \label{eq:het_cont}
		\sigma = exp(\pmb{\alpha}^{T}\mathbf{Z^{(1)}})
	\end{equation}
	Notice that the previous formula implies that equation (\ref{eq:dist_cont}) can be re-written in the following form:
	\begin{equation} \label{eq:dist_cont1}
			f(y^{*}| \mathbf{X}, \mathbf{Z}, \pmb{\eta}) = \phi(v + \pmb{\alpha}^{T}\mathbf{Z^{(1)}})
	\end{equation}
	where $\mathbf{Z^{(1)}}$ is the design matrix that maps the random effects $\pmb{\alpha}$. Notice that equation (\ref{eq:dist_cont1}) effectively corresponds to a model that includes random intercepts at level $1$. 
	
	
	
	\item \textbf{Dichotomous:} \\
	In a more straightforward way, we model over- or under-dispersion by modifying equation (\ref{eq:link_dich}), to include random intercepts at level $1$, in the following form:
	\begin{equation} \label{eq:link_dich1}
		\begin{split}
			\mu &= P[y=1 | \mathbf{X}, \mathbf{Z}, \pmb{\eta}] \\
			&= \pi \\
			&= h(\kappa - v + \pmb{\alpha}^{T}\mathbf{Z^{(1)}})
		\end{split}	
	\end{equation}
	
	
	
	\item \textbf{Ordinal, and discrete time duration:} \\
	Similar to the dichotomous case, by including random intercepts at level $1$ in equation (\ref{eq:link_ord1}), we can model over- or under-dispersion:
	\begin{equation} \label{eq:link_ord3}
		\begin{split}
			\mu_{s} &= P[y \leq y_{s} | \mathbf{X}, \mathbf{Z}, \pmb{\eta}] - P[y \leq y_{s-1} | \mathbf{X}, \mathbf{Z}, \pmb{\eta}] \\
			&= h(\kappa_{s} - v_{s} + \pmb{\alpha}^{T}\mathbf{Z^{(1)}}) - h(\kappa_{s-1} - v_{s-1} + \pmb{\alpha}^{T}\mathbf{Z^{(1)}})
		\end{split}
	\end{equation}
	A similar parametrization can be used for discrete time duration.


	
	\item \textbf{Counts, and continuous time duration:} \\
	Finally, modifying equation (\ref{eq:link_count}) allow us to model over- or under-dispersion under a counts model:
	\begin{equation} \label{eq:link_count1}
		\begin{split}
			\mu &= E[y | \mathbf{X}, \mathbf{Z}, \pmb{\eta}] \\
			&= \lambda \\
			&= exp(v + \pmb{\alpha}^{T}\mathbf{Z^{(1)}})
		\end{split}
	\end{equation}

\end{enumerate}






\subsection{Structural model for the latent variables} \label{s_sect:struct}
The structural model for the latent variables has the form:
\begin{equation} \label{eq:structural_model}
	\def\sss{\scriptstyle}
	\setstackgap{L}{12pt}
	\def\stacktype{L}
	\pmb{\eta} = \stackunder{\mathbf{B}}{\sss (M \times M)} \stackunder{\pmb{\eta}}{\sss (M \times 1)} + \stackunder{\pmb{\Gamma}}{\sss (M \times Q)} \stackunder{\mathbf{W}}{\sss (Q \times 1)} + \stackunder{\pmb{\zeta}}{\sss (M \times 1)}
\end{equation}
where $\mathbf{B}$ and $\pmb{\Gamma}$ are parameter matrices that maps the relationship between the latent variables $\pmb{\eta}$, and the vector of "stacked" covariates $\mathbf{W}$, respectively; $\pmb{\zeta}$ is a vector of errors or disturbances, and $M = \sum_{l} M_{l}$. Notice that while equation (\ref{eq:structural_model}) resembles to single-level structural equation models, the main difference lies in the fact that the latent variables may vary at different levels. Additionally, considering that $\pmb{\eta}$ has no feedback effects, and it is permuted and sorted according to the levels, $\mathbf{B}$ is defined as a strictly upper triangular matrix. In this regard, it is important to mention that,
\begin{enumerate}
	\item The absence of feedback loops implies that the method deals with non-recursive models, i.e. none of the latent variables are specified as both causes and effects of each other \cite{Kline_2012}; {\color{red} this in turn allows the easy estimation of the model parameters}.
	
	\item The strictly upper triangular structure reveals that the framework does not allow latent variables to be regressed on lower level latent or observed variables, as such specification is more related to the use of formative, rather than reflective, latent variables. For a detail explanation on the topic refer to \citet{Edwards_et_al_2000}.
\end{enumerate}
Notice, however, the previous restrictions does not hinder the ability of the method to model contextual effects, after controlling the lower level compositional effects. For examples of such refer to Appendix \ref{appA:additional}.



\subsection{Distribution of the latent variables} \label{s_sect:dist_lv}
Finally, to fully specify the framework, and provide a scale for the latent variables, we have to make assumptions for either the distribution of the disturbances $\pmb{\zeta}$ or the latent variables $\pmb{\eta}$. If our research interest lies in the structural equation model, it is more convenient to make assumptions for the distribution of the disturbances; otherwise, we make assumptions for the distributions for the latent variables. 

Furthermore, as in the hierarchical framework, it is assumed the latent variables at different levels are independent, whereas latent variables at the same level may present dependency. In that sense, we presume all latent variables at level $l$ to have a multivariate normal distribution with zero mean and covariance matrix $\Sigma_{l}$, i.e. $\pmb{\eta}^{(l)} \sim MVN(\mathbf{0}, \pmb{\Sigma}_{l})$. It is important to emphasize that, while the multivariate normal distribution is widely used in these settings, it is not the only distribution that can be assumed. \citet{Rabe_et_al_2003a} have provided evidence that it can be even left unspecified, by using non-parametric maximum likelihood estimation.




\section{Model identification and fit} \label{sect:model_extra}


\subsection{Identification} \label{s_sect:identification}
{\color{red}(work in progress) \\
The structure of the latent variables is specified by the number of levels L and the number of latent variables Ml at each level. A particular level may coincide with a level of clustering in the hierarchical dataset. However, there will often not be a direct correspondence between the levels of the model and the levels of the data hierarchy.

}


\subsection{Model fit} \label{s_sect:fit}
{\color{red}(work in progress) \\
}




\section{Relationship with other modeling schemes}

From section \ref{sect:definition}, it is evident that the GLLAMM framework shares some common ground, and even extends, some of the most important modeling schemes, such as the GLM, GLMM, SEM, and the Generalized Latent Model framework, from which the Item Response Theory Model (IRT) stand out.

\subsection{Generalized Linear and Mixed Models}

The Generalized Linear Model (GLM) framework, presented by \citet{Nelder_et_al_1972}, and further developed by \citet{Nelder_et_al_1989}, was formulated with the purpose of expanding the linear regression model to other types of responses, like dichotomous, and counts. The scheme generalizes the linear model by "linking" the mean response variable to a linear predictor, and further allowing the magnitude of the variance, of each measurement, to be a function of its predicted value. Finally, the scheme is fully defined after selecting a distribution, from the exponential family, to model the distribution of the response variable.

As expressed in the previous paragraph, the GLM framework fixes the relationship of the modeled dispersion to the mean value, e.g. in the counts case $\mu = \lambda$, and $v(\mu) = \lambda$. However, in practice, this assumption is often violated as the data can present over- or under-dispersion. Even in the continuous response case, where the mean and variance function are not related, the model assumes that the errors are homoscedastic, identical and independently distributed. However, this assumption is often violated when the units of analysis are correlated or belong to a cluster, e.g. when students are nested in schools, and these are further nested in districts or states.

It is important to mention that, while the GLM framework can model heteroscedasticity, over- or under-dispersion, it does it in a way that does not allow them to be dependent on covariates, something that might be of interest for a researcher.

Given the restrictions of GLM, the Generalized Linear Mixed Model (GLMM) framework was developed. The method handled the hierarchical or clustered structure in the data, and in doing so, indirectly modeled the heteroscedasticity, over- or under-dispersion by adding latent variables, called "random effectsâ€, to the linear predictor. Under the framework, the random variables are often interpreted as the effects of unobserved covariates, at different levels, that induce dependence among lower-level units \cite{Rabe_et_al_2012}, and can be further explained by additional observed covariates. 

From the previous description, it is easy to notice that the GLLAMM framework uses the same generalization and distributional assumptions, for the response variables, as the GLM; while it borrows the idea of modeling the hierarchical or clustered structure in the data, by including random effects; from the GLMM. However, it is clear that the GLLAMM further generalize both, by allowing the framework to model measurement error at different levels of the hierarchy in the data.



\subsection{Structural Equation Models}

Considering that, in practice, researchers are often faced with variables that cannot be measured directly or reflect measurement error, e.g. intelligence, depression, student abilities, among other; the statistical literature was instigated to develop methods that can handle such data characteristics. 

{\color{red}(work in progress) \\
The disciplinary seeds of Structural Equation Models (SEM) were set by \citet{Spearman_1904}, with a factor model on intelligence testing, passing through \citet{Wright_1920}, with a path analysis in the context of genetic and biology, to finally land in the sociological field, with the work of \citet{Blalock_1961}.

to include several features of the previous modeling scheme, i.e. generalized linear mixed models, the framework is characterized by the fact that it is a method that can impute relationships between unobserved factors or latent variables, and observable or manifest variables. Under this framework, it is assumed that such "common factors" are responsible for the variation and dependence in the manifest variables.

mention Factor Models, Item Response Theory and Generalized Latent Models, and Multilevel Structural Equation Models
\ref{s_sect:dist_lv}


multilevel structural equation models represent a synthesis between multilevel regression models and structural equation models. Considering that 
}




\section{Advantages and Disadvantages}
{\color{red}(work in progress)}
