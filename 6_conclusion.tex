\chapter{Conclusion and Discussion} \label{cap:conclusions}

\section{Discussion}

\section{Conclusions}

Consequently, all of the above just show the NCP largely improved the performance of the MCMC chains under our implementation, for all models and almost all of the parameters. It is important to point out, the result did not extend to the sub-dimensions' correlation parameters, where no large difference in performance was observed between the CP and NCP. On this matter, the issue was not related to a lack of identification of said parameters, as we were careful to ensure the fulfillment of this requirement.

why we have this: we can notice that the SOLV model estimate non-negligible positive correlations for some of replicas with sample sizes greater than $100$. This just indicates that for larger sample sizes, some residual correlation remains present, even when the model considers a higher order latent variable. One explanation for this could be that the model severely underestimated the loadings. The true values for the parameters were not within any of the compatibility intervals (that is why we registered higher levels of $\text{RMSE}_{B}$ in table \ref{tab:SOLV_RMSE_loads}).

From the figures we notice the model manages to produce a rather well depiction of the true ICC and IIF curves. This means that the model allow us to correctly recover the item's psychometric characteristics, a trait of high relevance for the development of instruments.

no difference in retrodictive accuracy is observed between the CP and NCP. Moreover, they reveal the predictive uncertainty is higher within rather than between the replicas, that is, the models predicted the data in a similar manner across replicas.

The NCP being slightly faster than the CP is important, as the non-centered parametrization is more complex, and requires the sampling of more parameters than the centered counterpart. This just means that improving the performance of the MCMC, through a more complex model as the NCP, does not come with a cost on running time.

No invariance assessment has been made, No multigroup analysis, no clustering effects

All of the above results just resonates with the patterns obtained in the previous chapter. However, in contrast with the results of the simulation study, some of the structural regression parameters (not shown) registered better performance under the CP, rather than the NCP. Among these set of covariates were age, disability, and both of the experience variables. Nevertheless, the disagreement was not unanimous, as the parameters showed ``healthier" chains with larger effective sample sizes, but \texttt{Rhat} values above the recommended threshold, indicating a lack of convergence. This result resonates with \citet{Papaspiliopoulos_et_al_2007}, who stated that the success of the NCP strategy was largely dependent on the specifics of the models and data.

Moreover, it is surprising this pattern of behavior was not replicated on the SOLV model, where all of the structural parameters seemed to be more ergodic under the NCP. The latter lead us to think, the previous patterns resulted from the use a possible miss-specified model.

In conclusion, given the results obtained in this section, and section  \ref{sub_sect:ergodicity_simulation} of the previous chapter, conditional on the selected number of iterations, the non-centered parametrization was the only one to ensure the GLLAMM parameters attained ergodicity.

The full benefit of a DAG comes from using it to design both the collection of data and the structure of our statistical models. However, we recognize the sampling design for contrast was not great. The research realized that in order to produce better inferences, especially related to contrast of variables, a more careful sample design (equal number of individuals within each levels per covariate). However, no bias was induces from a wrongful design.


Consequently, both models produce similar encodings of the data, therefore, the decision of choosing one over another rest now on a more theoretical ground.

\section{Future development}

It is important to point out, the result did not extend to the sub-dimensions' correlation parameters, where no large difference was observed between the CP and NCP. On this matter, the issue was not related to a lack of identification of said parameters, as we were careful of ensuring this requirement.

Investigate this, maybe you need to use Variational Inference methods. CP versus NCP is a false dichotmy, because as authors mentioned they work more in a complementary way, therefore methods that seeks they integrations may need to be the staple of IRT models.

One explanation for this could be that both parametrizations achieved what is called a \textit{local convergence} \cite{Depaoli_2021}, that is, the chains appear to be stable in the range of the iterations (at least observed in the NCP). However, given the consistent results across replicas, the researcher is led to think that even with all the issues present under the CP, the chains managed to visit the posterior distribution in a way, that allows the method to produce a proper estimation of the parameters. Moreover, we are also led to think, the preceding patterns of recovery capacity are the result of using the HMC algorithm with a higher rejection criteria (\texttt{adapt\_delta}$=0.99$) and weakly regularizing priors. The previous chapter has described the benefits of these factors separately, so it is sensible to assume that used in conjunction, they could benefit the posterior exploration, and therefore, the recovery capacity of the method. Further investigations manipulating these conditions could be of relative importance. For example, investigate the recovery capacity under HMC and Gibbs sampling, under CP and NCP with no regularizing priors or adapt delta. as the results could be due to the HMC or the regularizing priors, and we cannot observe the true benefits of the change to NCP.