\chapter{Bayesian estimation } \label{chap:estimation}

The practical use the GLLAMM developed in chapter \ref{chap:framework} requires the estimation of all of the items and individuals' dimensions, loadings, regression and structural parameters. These can be obtained within two frameworks: the frequentist and bayesian. 

The current chapter center its attention on describing the bayesian estimation procedure, using the Markov Chain Monte Carlo method (MCMC). For a full development of GLLAMM under the frequentist framework refer to Rabe-Hesketh and colleagues \cite{Rabe_et_al_2004a, Rabe_et_al_2004b, Skrondal_et_al_2004a, Rabe_et_al_2012}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Benefits and shortcomings}

\subsection{Why Bayesian?} \label{sub_sect:goods}

The reasons on why bayesian statistics is attractive to perform the parameters' estimation of any model, and especially for the GLLAMM developed in chapter \ref{chap:framework}, are:

\begin{enumerate}	
	\item It is built on a simulation-based estimation method, therefore, it can handle all kinds of priors and data-generating processes \cite{Fox_2010}. This is especially useful with highly complex and over-parameterized models, where other methods are unfeasible or work poorly \cite{Baker_1998, Kim_1999}. 
	
	\item While the likelihood functions are used to define the posterior sampling distributions, they can also be used in a generative way. The likelihood for the data, and priors for the parameters, form the basis to produce samples from the posterior distribution. However, they can also be used to simulate observations, allowing us to test the ability of the method/data to recover the parameters of interest \cite{McElreath_2020}.
	
	\item The bayesian estimates are at least as good as its frequentist counterparts \cite{Baker_1998, Wollack_2002, Hsieh_2010}. This is true when the method uses uninformative `flat' priors. However, because the procedure allow us to integrate prior knowledge about the parameters, beyond the observed responses, it can produce results even in scenarios where the Maximum Likelihood methods (ML) have issues of non-convergence or improper estimation \cite{Skrondal_et_al_2004a, Fox_2010, McElreath_2020}. Examples of such are: 
	
	\begin{enumerate}
		\item when we have small sample sizes.
		
		\item when individuals have null scores or aberrant response patterns \cite{Hambleton_et_al_1991a, Azevedo_2003}. The latter happens when examinees answered some relatively difficult and discriminating items correctly, while answering some of the easiest incorrectly.
		
		\item when parameters need to be confined to a permitted space, e.g. the estimation of positive unique factors variances \cite{Martin_et_al_1975}.
		
		\item when we need to estimate parameters under sparse data, where the asymptotic theory is unlikely to hold \cite{Fox_2010};
		
	\end{enumerate}
	
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Are you sure there's nothing wrong?} \label{sub_sect:bads}
Off course the bayesian framework has shortcomings, among them:

\begin{enumerate}	
	\item It exposes the user to somewhat-arbitrary decisions about the running of the chains, in order to ensure a proper performance, e.g. how many iterates does the chain need to achieve precise estimates?, what is the right size for the burn-in and warm-up phases?, how should the thinning procedure be performed, if any?, should we follow the same procedure for all parameters of interest?, among others \cite{Skrondal_et_al_2004a}. 
	
	\item The user can include all type of information through the priors distributions, apparently making their elicitation convenient for manipulation, towards the use of highly informative priors.
	
	\item Multiple options are available to evaluate the performance of the method, and most of them are visual, making it hard to assess if a proper posterior investigation have been made \cite{Gelman_et_al_1996a}. More specifically, the user has multiple options to assess if the chain achieves the three requirements of a good performance: stationarity, convergence, and good mixing \cite{McElreath_2020}. 
	
	\item The procedure makes it hard to discover parameters' lack of identification \cite{Skrondal_et_al_2004a}. Inadequate mixing of the chain could lead us to think unidentified parameters have been estimated with precision, when in fact what we have are `flat' posteriors \cite{Keane_1992}.
	
	\item Oftentimes the posterior sampling geometry of the model makes it hard to find proper solutions for the parameter space, no matter the rotation/rescaling of the parameter, or the amount of data \cite{Betancourt_et_al_2013}. This is especially true in complex hierarchical models.
	
	\item The greater the complexity of the model, the harder it is to communicate/share the implementation with other scientist. This is especially true, when researcher re-parameterize the model to solve the previous shortcoming \cite{McElreath_2020}.
	
	\item The procedure usually requires more time to achieve a proper solution, compared to the classical methods. This is especially true in models with high complexity \cite{Tarazona_2013, Rivera_2019}.
\end{enumerate}

Although some of the previous shortcomings have made the Bayesian procedure a ``controversial" implementation, most of them already have acceptable solutions. 

For the first point, a popular approach is to use a large number of iterates, burn-in and thinning processes. This is mostly applicable under the Metropolis-Hastings and Gibbs sampling algorithms. However, recent solutions, like the Hamiltonian Monte Carlo (HMC) \cite{Betancourt_et_al_2013}, is less reliant on the decision of selecting these features, as it implements a different sampling mechanism (see section \ref{sub_sect:hmc}). 

On the second point, the literature has indicated that priors can be used in a subjective manner\footnote{see \citet{McElreath_2020} (Chapter 2, pp. 36), Rethinking section ``Prior, prior pants on fire", for an interesting stance contrary to this statement.}. However, because they can be considered a part of the model assumptions, they can be chosen, evaluated, and revised as any other component of the model, through the use of prior predictive simulations and/or sensitivity analysis \cite{McElreath_2020} (see section \ref{sub_sect:prior_pred}).

About the third point, it is well accepted that the visual assessment of stationarity and convergence is easier, and these procedures usually has additional support from statistics like \texttt{Rhat} \cite{Gelman_et_al_2014}. On the contrary, a visual evaluation of `good' mixing remains as a hard task. Recent approaches have taken a more proactive stance on the latter, seeking to increase the possibility of a well mixed chain by changing the posterior sampling geometry of the model \cite{Papaspiliopoulos_et_al_2003, Papaspiliopoulos_et_al_2007, Betancourt_et_al_2013, McElreath_2020} (see section \ref{sect:noncenter}).

On the fourth point, the most common solution is to use regularizing priors, i.e. priors that are more `skeptical' of wider parameter spaces \cite{McElreath_2020}. However, it is important to mention, there are scenarios where one achieves poor parameter estimates, even in the presence of `enough' data and regularizing priors, but this shortcoming is also applicable to the classical estimation procedures, e.g. the estimation of the variance parameters in random effects models \cite{Skrondal_et_al_2004a}.

About the fifth point, as it was mentioned in previous paragraphs, a recent approach to solve this issue is to change the posterior sampling geometry of the model. This means to re-parameterize the model in a way that removes the dependence of the parameters on other sampled parameters, or even, produce sample mechanisms located in a continuous between a centered (CP) and non-centered parametrization (NCP), e.g. Interleaved HMC (iHMC) or Variational Inference (VI) \cite{Gelfand_et_al_1995, Gelfand_et_al_1996, Papaspiliopoulos_et_al_2003, Papaspiliopoulos_et_al_2007, Betancourt_et_al_2013, Gorinova_et_al_2019} (see section \ref{sect:noncenter}).

Finally, the sixth and seventh points can be considered the `price' a scientist has to pay, to be able to fit models that conforms better with the observed data generating processes. Although, recent developments are striving to improve upon reducing the latter, i.e. the required running time.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Bayesian GLLAMM for dichotomous outcomes} \label{sect:model}

\subsection{Posterior distribution}

Denoting $\mathbf{Y}$ as the observed data and $\pmb{\Omega} = \{ \pmb{\beta}, \pmb{\Lambda}, \pmb{\Theta}, \pmb{\Psi}, \pmb{\Gamma} \}$, i.e. all the parameters declared in section \ref{s_sect:response} and \ref{s_sect:struct}; the posterior distribution is obtained using the Bayes theorem, in the following way:
%
\begin{equation} \label{eq:posterior1}
	\begin{split}
		P(\pmb{\Omega} \; | \; \mathbf{Y}) = \frac{ P( \mathbf{Y} \; | \; \pmb{\Omega} ) \; P( \pmb{\Omega} ) }{ \int P( \mathbf{Y} \; | \; \pmb{\Omega} ) \; P( \pmb{\Omega} ) \; d\pmb{\Omega} } \\
	\end{split}
\end{equation}

\noindent this is possible since the Bayesian approach makes no distinction between latent variables and parameters. All of them are considered random quantities \cite{Skrondal_et_al_2004a}. Furthermore, since inference only requires representing the likelihood of the data $P( \mathbf{Y} \; | \; \pmb{\Omega} )$ and the prior distribution $P( \pmb{\Omega} )$; and because the denominator is just a (hard to calculate) constant, the posterior can be determined up to a normalizing constant, without loss of generality:
%
\begin{equation} \label{eq:posterior2}
	\begin{split}
		P(\pmb{\Omega} \; | \; \mathbf{Y}) &\propto P( \mathbf{Y} \; | \; \pmb{\Omega} ) \; P( \pmb{\Omega} )
	\end{split}
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Prior distributions} \label{sub_sect:priors}

Similar to \citet{Patz_et_al_1999}, we use an independent distributional structure for the joint priors of the parameters, at the highest level of the GLLAMM:
%
\begin{equation} \label{eq:priors}
	\begin{split}
		P( \pmb{\Omega} ) & = P( \pmb{\beta}, \pmb{\Lambda}, \pmb{\Theta}, \pmb{\Psi}, \pmb{\Gamma} ) \\
		%
		&= P( \pmb{\beta} ) \; P( \pmb{\Lambda} ) \; P( \pmb{\Theta} ) \; P( \pmb{\Psi} ) \; P( \pmb{\Gamma} ) \\
		%	
		&= P( \pmb{\beta} ) \; \left[ P( \pmb{\alpha} ) \; P( \pmb{\lambda} ) \right] \; \left[ P( \pmb{\eta} ) \; P( \pmb{\theta} ) \right] \; \left[ P( \pmb{\Psi}_{\eta} ) \; P( \pmb{\Psi}_{\theta} ) \right] \; \left[ P( \pmb{\Gamma}_{\eta} ) \; P( \pmb{\Gamma}_{\theta} ) \right]
	\end{split}
\end{equation}

However, giving the hierarchical and cross-classified structure of the model, the lower level priors will also depend on further parameters\footnote{Because of this sequential model specification, it is said the priors also have a ``hierarchical" structure.}, e.g. variances and covariances of the latent variables. These are known as \textit{hyper-parameters}, and their prior distributions as \textit{hyper-priors}. Because of the previous, we are not going to detail their lower level representation, as they are highly dependent on the specifics of the model.

Finally, as recommended by several authors the priors will be mildly informative \cite{McElreath_2020, Fujimoto_2020, Tarazona_2013, Jiao_et_al_2012, Azevedo_2003, Wollack_2002}, model-specific and determined by a prior predictive investigation. See section \ref{sub_sect:prior_pred} for the prior elicitation procedure followed in the current research. 

Chapter \ref{chap:simulation} and \ref{chap:application} will show the elicitation of priors, in the context of a simulated and real data set, respectively.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Likelihood}

Following \citet{Rabe_et_al_2004a}, the likelihood function is build in a recursive way. 

\noindent First, we replace the structural model (\ref{eq:structural_model1}) into the linear predictor (\ref{eq:linear_predictor3}):
%
\begin{equation} \label{eq:lin_pred}
	\begin{split}
		v_{jkd} &= \mathbf{X}_{j} \pmb{\beta} + ( \mathbf{I} - \pmb{\Psi} )^{-1} \left[ \pmb{\Gamma} \mathbf{W} + \pmb{\zeta} \right] \; \pmb{\Lambda} \; \mathbf{H}_{j}
	\end{split}
\end{equation}

\noindent Second, the linear predictor and inverse-link function (\ref{eq:response_dich1}) are used to construct the systematic part of the response (\ref{eq:systematic}), i.e. its expected value. Here we use a logit link for pedagogical purposes:
%
\begin{equation} \label{eq:prob}
	\begin{split}
		\pi_{jkd} &= \frac{ \text{exp}(\tau_{k} + v_{jkd}) }{ 1 + \text{exp}(\tau_{k} + v_{jkd}) } = \frac{ \text{exp}(v_{jkd}) }{ 1 + \text{exp}(v_{jkd}) }
	\end{split}	
\end{equation}

\noindent Third, the expected value is used in the distributional part (\ref{eq:distributional}), in the following form:
%
\begin{equation} \label{eq:dist}
	\begin{split}
		f \left( y_{jkd}=1 \; | \; \mathbf{X}, \mathbf{W}, \pmb{\Omega} \right) &= \pi_{jkd}^{n} (1 - \pi_{jkd})^{1-n}
	\end{split}
\end{equation}

\noindent Fourth, considering assumptions (M1) and (M2) described in section \ref{s_sect:assump}, we produce the level-1 likelihood:
%
\begin{equation} \label{eq:lik1}
	f \left( \mathbf{y}=\mathbf{1} \; | \; \mathbf{X}, \mathbf{W}, \pmb{\Omega} \right) = \prod_{j=1}^{J} \prod_{d=1}^{D} \prod_{k=1}^{K} f \left( y_{jkd}=1 \; | \; \mathbf{X}, \mathbf{W}, \pmb{\Omega} \right)
\end{equation}

\noindent Fifth, we define the marginal likelihood at levels $l$ and $m$, conditional on the latent variables at levels $l+1$ and $m+1$, in the following form:
%
\begin{equation} \label{eq:lik2}
	f^{(l)}_{(m)} \left( \mathbf{y}=\mathbf{1} \; | \; \mathbf{X}, \mathbf{W}, \pmb{\Omega} \right) = \int \left[ \prod f^{(l-1)}_{(m-1)} \left( \mathbf{y}=\mathbf{1} \; | \; \mathbf{X}, \mathbf{W}, \pmb{\Omega} \right) \right] \; P( \pmb{\Theta}^{(l)}_{(m)} ) \; d\pmb{\Theta}^{(l)}_{(m)}
\end{equation}

\noindent where the product inside the brackets is over all units in level $(l-1)$ and $(m-1)$, the first level is defined in equation (\ref{eq:lik1}), and $P( \pmb{\Theta}^{(l)}_{(m)} )$ are the prior distributions for the latent variables at level $l$ and $m$, with $\pmb{\Theta}^{(l)}_{(m)} = [\pmb{\eta}^{(m)}, \pmb{\theta}^{(l)}]$. Finally, we define the likelihood as:
%
\begin{equation} \label{eq:lik3}
	\mathcal{L}(\mathbf{X}, \mathbf{W}, \pmb{\Omega}) = \prod_{m=2}^{M+1} \prod_{l=2}^{L+1} f^{(l)}_{(m)} \left( \mathbf{y}=\mathbf{1} \; | \; \mathbf{X}, \mathbf{W}, \pmb{\Omega} \right)
\end{equation}

\noindent and the log-likelihood as:
%
\begin{equation} \label{eq:loglik}
	\ell(\mathbf{X}, \mathbf{W}, \pmb{\Omega}) = \log \mathcal{L}(\mathbf{X}, \mathbf{W}, \pmb{\Omega})
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Model identification} \label{sect:identification}

As indicated by \citet{Rabe_et_al_2004a}, in order to fully specify the model and provide a scale for the latent variables, we have to make assumptions for either the distribution of the disturbances $\pmb{\zeta}$, or the distribution of one or more of the latent variables $\pmb{\Theta}$. On the other hand, as point out by \citet{Fujimoto_2018b} and several others authors, we could also set restrictions for one or more of the loadings in $\pmb{\Lambda}$. The last is more prevalent in frequentist software packages like Winsteps \cite{Winsteps2021}.

Furthermore, as it is hinted by equation (\ref{eq:lik3}), it is assumed the latent variables at different levels are independent from each other, whereas latent variables at the same level may present dependency. In case of the latter, we presume the latent variables at the same level have a multivariate normal distribution with a mean and covariance structure determined by equations (\ref{eq:structural_model2}) and (\ref{eq:structural_model3}). In the case of the covariance matrices, these are determined by the covariance of the specific disturbances $\pmb{\zeta}$. 

Chapter \ref{chap:simulation} and \ref{chap:application} will show the model identification strategy in the context of a simulated and real data set, respectively.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Computational implementation} \label{sect:comp_imp}

\subsection{Hamiltonian Monte Carlo} \label{sub_sect:hmc}

For years the state-of-the-art platform for Bayesian statistical modeling have been the BUGS\footnote{Bayesian inference Using Gibbs Sampling} project \cite{Lunn_et_al_2000, Lunn_et_al_2009}, with its WinBUGS and OpenBUGS implementations. However, a more recent participant JAGS\footnote{Just Another Gibbs Sampling} \cite{Plummer_2003} has gain traction, due to its cross-platform capabilities. In any case, both platforms are not that different form each other. Both use two of the most popular and successful algorithms for performing MCMC: the Metropolis-Hastings \cite{Metropolis_et_al_1953, Hastings_1970} and Gibbs Sampling \cite{Geman_et_al_1984} algorithms.

In general lines, the Metropolis algorithm follows a two-step procedure: (i) it produces a new proposal for a parameter's value, and (ii) it evaluates the proposal against the current, accepting the new value if it is more likely under the posterior distribution. On the other hand, the Gibbs sampling uses a similar procedure, but it gains efficiency by exploiting the knowledge behind the target distribution. The latter improvement catapulted the Gibbs sampler into the workhorse of high dimensional Bayesian computing. 

However, both methods remain as highly random procedures, and because of it, they still have important limitations. The most important of them all is that they do not yield independent and identically distributed samples (iid). This in turn means, the exploration of the posterior is made through a series of (sometimes highly dependent) values, causing the MCMC chain to converge to the target distribution only in the long run, i.e. when the number of iterations approach infinity ($t \rightarrow \infty$) \cite{Gelman_et_al_2014}. 

In this setting three solutions have been proposed within the context of these algorithms, and oftentimes the aforementioned software packages use them in conjunction. The first consist on improving the sampling mechanism by using a Hybrid MCMC method. A good example is the ``Metropolis-within-Gibbs" algorithm \cite{Muller_1991}. The second consist on setting a warm-up phase that seeks to adapt the proposal distributions to favor the exploration of the posterior. Finally, the third consist on defining the number of iterates, burn-in and thinning processes in a way that it reduces the serial dependencies in the samples. 

Nevertheless, the aforementioned solutions, while useful, do not solve all issues related to the MCMC chain's performance, as these can remain biased in subtle ways, that are more harder to identify \cite{McElreath_2020}. Therefore, researchers have decided instead to propose new improved algorithms. 

Is in this context were the Hamiltonian Monte Carlo or Hybrid Monte Carlo (HMC) was proposed by \citet{Duane_et_al_1987}, using the theory of Hamiltonian Dynamics. While the full representation of method is out of the scope of this research, we can still make a high-level description of its process, with purpose of point out its benefits and shortcomings. 

Assuming we have continuous distributions and the partial derivatives of the log-density function (the gradient) exists, the method iterates the updating of two vector spaces of a particle \cite{Neal_2011, McElreath_2020}. First, it samples new values for the particle's momentum vector, independent of the current values of its position vector, i.e. it gives the particle a random ``flick". In the second iteration, using Hamiltonian dynamics, a Metropolis update is performed to propose a new position vector for the particle. In this sense, one can say the HMC runs a small physics simulation, where the position of the particle denotes the current parameter values in the Markov chain, the momentum denotes the proposed path to a new set of values, and the log-posterior provides the ``friction-less" surface over which the particle moves, where the gradient defines its curvature \cite{McElreath_2020}.

In principle, because HMC produce ``more informed" proposals, it will accept all of them. In practice however, HMC uses a rejection criterion, that inform us when the method was not able to maintain the ``balance" of the system, producing a bad numeric approximation (see section \ref{sect:noncenter} for an example). For more on the background theory on Hamiltonian Dynamics and specifics about the HMC algorithm refer to \citet{Neal_2011} and \citet{Betancourt_et_al_2013}.

All of this just tells us that HMC is a highly complex algorithm. However, as \citet{McElreath_2020} point out, the Gibbs strategy got its improvement over the Metropolis-Hastings by being less random, not more. And in that sense, HMC pushes this principle to a greater length, but manages to improve the efficiency of the MCMC procedure. This is especially true in cases where ordinary Metropolis or Gibbs sampling cannot make a proper exploration of the parameter space, e.g. with highly correlated parameters or with models with hundreds or thousands of parameters, like complex hierarchical models. Moreover, as HCM is more efficient, it requires less number of iterations to make a proper posterior investigation \cite{McElreath_2020, Gelman_et_al_2014} 

Off course, this comes with a cost. The methods is more computationally intensive than the previous. However, because of the efficiency improvement and the need of less number of iterations, the method requires less computer time in total, even when each individual sample needs more.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Where can I find this magical software?} \label{sub_sect:software}

\texttt{Stan} \cite{Stan2020} is the software package that will provide us with the machinery of HMC. Furthermore, the results produced from the software will be analyzed with \texttt{R} \cite{R2015, RStan2020}, and its integration packages. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{What about burn-in and thinning?} \label{sub_sect:burn}

Since HMC uses a different approach and produces more informative proposals, setting specific burn-in and thinning processes is no longer necessary.

However, the method does require to perform a warm-up procedure to adapt sampling, and to tune in two parameters of the algorithm: the number of steps, and the step size \cite{Stan2020}. These parameters are used to make a discrete approximation of the momentum vector, i.e. the path of the particle \cite{Neal_2011, Betancourt_et_al_2013}. 

Notice, this phase is similar to a procedure performed in JAGS, where the proposal distribution gets ``tuned up" to improve the posterior investigation. However, the similarities end there. The warm-up samples are not representative of the target posterior distribution, no matter how long the iterations continue \cite{McElreath_2020}. Finally, after the warm-up is finished, and assuming the adaption was successful, the method will sample directly from the target distribution.

In the current research, we will use the default values set in the software, i.e. a total of $2,000$ iterations, where $1,000$ of them will be spend on warm-up. Notice this departs (by far) from most of the literature on Bayesian IRT models, e.g. \citet{Fujimoto_2018a} used chains with $60,000$ iterations, where $15,000$ were discarded and the remaining were thinned in jumps of $3$; while \citet{Fujimoto_2018b} used $225,000$ iterations, with burn-in of $30,000$ and thinning with jumps of $15$; just to mention a few.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Initial starts} \label{sub_sect:starts}

Since the method requires starting values for the parameters, the author decided to allow the software to sample these from the priors defined in the model.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Prior elicitation} \label{sub_sect:prior_pred}

As stated in section \ref{sub_sect:bads}, because priors can be considered a part of the model assumptions, they can be chosen, evaluated, and revised as any other component of the model \cite{McElreath_2020}. On the other hand, as declared section \ref{sub_sect:priors}, the priors used in this research will be mildly informative \cite{McElreath_2020, Fujimoto_2020, Tarazona_2013, Jiao_et_al_2012, Azevedo_2003, Wollack_2002}, model-specific, and determined by a prior predictive investigation.

Multiple studies have pointed out the benefits of using mildly informative priors to reduce over-fitting, while allowing the model to learn regular features of the data, e.g. \citet{McElreath_2020, Gelman_et_al_1996b} and \citet{Jaynes_1985}. In contrast, the literature has emphasized the unintended consequences on the posterior, resulting from using highly uninformative priors, e.g. \citet{Seaman_et_al_2012}, and \citet{Gelman_1996}. 
%
\begin{figure}[!h]
	\centering
	\includegraphics[width=1\textwidth]{prior_elicitation}
	\caption[Prior predictive simulation. Examples of uninformative and mildly informative priors.]%
	{Prior predictive simulation. Examples of uninformative and mildly informative priors. The panels show the density of the probability of a binary outcome under: (A) uninformative prior on equation (\ref{eq:prior_el1}) and mildly informative prior on equation (\ref{eq:prior_el3}); and (B) uninformative prior on equation (\ref{eq:prior_el2}) and mildly informative prior on equation (\ref{eq:prior_el4}). Uninformative (black continuous lines), and mildly informative (blue discontinuous lines).}
	\label{fig:prior_elicitation}
\end{figure}

In the case pertaining our implementation, the reasons why we are using mildly informative priors, can be understood with a simple illustration. Consider an example similar to one outlined by \citet{Seaman_et_al_2012} and \citet{McElreath_2020}, where a simple latent model is defined as follows:
%
\begin{equation} \label{eq:prior_el1}
	\begin{split}	
		\theta &\sim N(0, 100) \\
		p &= \frac{ \text{exp}(\theta) }{ 1 + \text{exp}(\theta) }
	\end{split}
\end{equation}

\noindent where $\theta$ denotes a latent dimension, and $p$ denotes the probability of a binary outcome, defined by the logit-link function. For pedagogical purposes, we did not declared the distribution of the responses, as we wanted to see what this prior implied for their probability, i.e. the expected value of a Bernoulli distribution.

Panel (A), from figure \ref{fig:prior_elicitation}, shows the uninformative prior in equation (\ref{eq:prior_el1}) forces an unintended assumption on the expected value of the outcome (black continuous line), i.e. the model is now highly `skeptical' of probabilities that are not zero or one. Moreover, this means that we are effectively using highly regularizing priors, but opposite on how they are supposed to be used, i.e. to avoid visiting non-likely parameter spaces.

The scenario only gets equally bad with the presence of hyper-parameters, and even less extreme assumptions. Consider the following example:
%
\begin{equation} \label{eq:prior_el2}
	\begin{split}
		v &\sim \log N(0, 3) \\	
		\theta &\sim N(0, v) \\
		p &= \frac{ \text{exp}(\theta) }{ 1 + \text{exp}(\theta) }
	\end{split}
\end{equation}

\noindent where $v$ is distributed as a log-normal distribution ($v>0$). Figure \ref{fig:prior_elicitation}, panel (B), shows the uninformative priors in equation (\ref{eq:prior_el2}) forces another unintended assumption on the expected value of the outcome (black solid line), i.e. the model is now highly `skeptical' of probabilities that are not $p = \{0, 0.5, 1\}$. Again is like using regularizing priors ``in reverse".

Luckily, this can be solved using mildly informative priors, i.e. prior distributions that are not supplying any controversial information, that are consistent with the likelihood, and are strong enough to pull the data away from inappropriate inferences \cite{Gelman_et_al_2014}. Consider the following change to equation (\ref{eq:prior_el1}):
%
\begin{equation} \label{eq:prior_el3}
	\begin{split}	
		\theta &\sim N(0, 1) \\
		p &= \frac{ \text{exp}(\theta) }{ 1 + \text{exp}(\theta) }
	\end{split}
\end{equation}

\noindent where $\theta$ has a prior that is not only consistent with common applications on IRT, but it also does not force the expected value of the outcome to be as extreme as in the uninformative case. Notice the probability can be in the $[0,1]$ space, where extreme probability values are assumed less likely (see blue discontinuous line vs black solid line on panel (A) in figure \ref{fig:prior_elicitation}).

Similarly, in the presence of hyper-parameters we can set mildly informative priors in the following form:
%
\begin{equation} \label{eq:prior_el4}
	\begin{split}
		v &\sim \log N(0, 0.5) \\	
		\theta &\sim N(0, v) \\
		p &= \frac{ \text{exp}(\theta) }{ 1 + \text{exp}(\theta) }
	\end{split}
\end{equation}

\noindent where the blue discontinuous line on panel (B) of figure \ref{fig:prior_elicitation} shows its transformation into the expected value scale.

One can imagine that the procedure of prior elicitation will get more complicated with a larger number of parameter and hyper-parameters. Therefore, the use of prior predictive simulation will be a tool of high value, as in the aforementioned examples.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{To center or not to center} \label{sect:noncenter}

As pointed out by \citet{Betancourt_et_al_2013}, even the most simple hierarchical models present formidable pathologies, that no simple correction can be performed to visit the posterior distribution properly. This is true no matter the rotation/rescaling of the parameter, or the amount of data. 

A great example of this is what \citet{McElreath_2020} dubbed the Devil's funnel (depicted in figure \ref{fig:devil_CE_geom}), where the author shows that you do not need a complex model to start observing these issues. Consider the following joint distribution:
%
\begin{equation} \label{eq:devil}
	\begin{split}	
		v &\sim N(0, 3) \\
		\theta &\sim N(0, \text{exp}(v))
	\end{split}
\end{equation}

\noindent where $v$ can be interpreted as the \textit{hyperprior} of $\theta$, and $\theta$ as dependent on the samples of $v$. The latter is what the literature dubbed as the centered parametrization (CP).

This joint distribution might seem familiar, as bayesian hierarchical model practitioners often use it to ensure the standard deviation remains into the permitted parameter space ($\sigma \geq 0$). Similar types of requirements permeate IRT models. Moreover, it seems that any MCMC procedure would not have any issues exploring the posterior distribution of these parameters, as they are normally distributed and there are only two of them, but we would be wrong. The reader can find the \texttt{stan} and \texttt{jags} implementations for these examples in Appendix \ref{appC1_1:noncenter}. The \texttt{stan} implementation replicates the example stated by \citet{Betancourt_et_al_2013}.

Figure \ref{fig:devil_CE} show the chains resulting from implementing the model on equation (\ref{eq:devil}), through HMC (\texttt{stan}). For pedagogical purposes, the example was run without data, as the author wanted to emphasize the pathologies are present even before we feed the data to our model. However, its easy to extrapolate that these issues will remain present when data is available.

As one can see from the figure, the joint posterior distribution is not explored properly. The chains show no sign of being ``healthy", i.e. they do not show stationarity or convergence (top panels), nor a good mixing (middle and bottom panels). This is further supported by the \texttt{Rhat}, and effective sample sizes estimates \texttt{n\_eff} \cite{Gelman_et_al_2014}. The \texttt{Rhat} for all parameters were above one (recommended threshold), indicating the chains did not achieve convergence: the between-chain variability was larger than the within-chain variability. Furthermore, the effective samples sizes were $34$ and $293$ for $v$ and $\theta$, respectively; indicating the values of the chains remained highly correlated (see bottom panels). This is striking as one expects effective sample sizes closer to the actual number of iterations $3,000$ ($3$ chains with $1,000$ samples each, after warm-up).
%
\begin{figure}[h]
	\centering
	\begin{subfigure}
		\includegraphics[width=.7\linewidth]{1_trace_CE_simple}
	\end{subfigure}
	%
	\begin{subfigure}
		\includegraphics[width=.7\linewidth]{1_trank_CE_simple}
	\end{subfigure}
	%
	\begin{subfigure}
		\includegraphics[width=.7\linewidth]{1_acf_CE_simple}
	\end{subfigure}
	%
	\caption[The Devil's funnel. Centered Parametrization. Stan.]%
	{The Devil's funnel. Centered Parametrization. (Top) Trace plots for the iterations on three chains. (Middle) Trank plots for the same data. (Bottom) Auto-correlation Functions (ACF) plot for the iterations.}
	\label{fig:devil_CE}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Wasn't HMC the solution to this?}

HMC is a powerful MCMC algorithm, and its benefits stand the test of other scenarios, as detailed by multiple authors \cite{McElreath_2020, Gelman_et_al_2014}. However, the issue with this example goes a little bit farther than what the algorithm can actually overcome, and this is true also for the Metropolis and Gibbs sampler. Nevertheless, we will see HMC still manages to be efficient within the constrains of the problem.
%
\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\linewidth]{1_funnel_CE_simple}
	%
	\caption[Posterior sampling geometry. Centered Parametrization.]%
	{Posterior sampling geometry. Centered Parametrization. (A) HMC exploration, blue points are accepted samples, red points denote divergent transitions. (B) Metropolis/Gibbs exploration, blue points are samples.}
	\label{fig:devil_CE_geom}
\end{figure}

Figure \ref{fig:devil_CE_geom} shows the posterior sampling geometry of the model in equation (\ref{eq:devil}), for the HMC algorithm (\texttt{stan}, left) and Metropolis/Gibbs sampler (\texttt{jags}, right). 

The first thing to notice is the complexity of the joint posterior geometry, with a steep funnel shape as the values of $v$ gets smaller and smaller. This makes sense, as the exponential of larger negative values, force the standard deviation of $\theta$ to be narrower and narrower around its mean (zero). 

The second thing to notice is that HMC (left panel) still manages to successfully explore the steep parameter space of $v$ and $\theta$. This can be observed through the blue points that are scattered in most of the geometry, albeit some parts are less visited (the geometry corresponding to $\theta>0$). This does not happen under the Gibbs sampler. In fact, \texttt{jags} did not managed to escape the narrow funnel shape, no matter the number of iterations used in the adaptation, burn-in and sampling procedures\footnote{\texttt{stan} used $3$ chains with $1,000$ iterations for adaptation, and $1,000$ iterations for sampling. \texttt{jags} used $3$ chains with $5,000$ iterations for adaptation, $5,000$ iterations for burn-in, and $5,000$ iterations for sampling.} (panel B). Moreover, as shown in figure \ref{fig:devil_CE_simple_jags} (appendix), the traceplots indicate the chains are ``healthy", ignoring the clear lack of exploration of the posterior distribution.

Finally, although HMC did not fully explore the posterior, at least the method let us know which parts of the distribution did not manage to visit appropriately (see red points indicating divergent transitions). The last is important, because HMC gives us the opportunity to identify where can we improve our parametrization, something that is not available on Metropolis or Gibbs.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{So, how can we solve this?}

There are two proposed solutions for this issue: (i) use regularizing priors, and (ii) change the posterior sampling geometry. This section will outline the benefits of the first, as it is already a well study result; while is going to advocate for the benefits of the second, in the context of IRT models.

\subsubsection{Regularizing priors}

It turns out that the benefits of using regularizing priors can also be explained from a geometrical perspective. Consider the following change to equation (\ref{eq:devil}):
%
\begin{equation} \label{eq:devil_prior}
	\begin{split}	
		v &\sim N(0, 1) \\
		\theta &\sim N(0, \text{exp}(v))
	\end{split}
\end{equation}

\noindent notice now we have chosen a mildly informative prior for $v$. 
%
\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\linewidth]{2_funnel_CE_priors}
	%
	\caption[Posterior sampling geometry. Centered Parametrization with mildly informative priors.]%
	{Posterior sampling geometry. Centered Parametrization with mildly informative priors. (A) HMC exploration, blue points are accepted samples, red points denote divergent transitions. (B) Metropolis/Gibbs exploration, blue points are samples.}
	\label{fig:devil_prior_geom}
\end{figure}

Figure \ref{fig:devil_prior_geom} shows the joint posterior sampling geometry of equation (\ref{eq:devil_prior}), for the HMC algorithm (\texttt{stan}, left) and Metropolis/Gibbs sampler (\texttt{jags}, right). 

The first thing to notice from the figure is that the geometry available for exploration seems more broad. However, what is actually happening is that by adding information about $v$, we are ``zooming" into the posterior geometry observed in figure \ref{fig:devil_CE_geom}, according to the range of the new priors. This further benefits the exploration of the posterior, as extreme ranges don't have to be visited from the start, e.g. the narrow funnel in the range $[-6,-2]$ of $v$ in figure \ref{fig:devil_CE_geom}.

The second thing one can notice is that HMC does not ``loose time" exploring sections of the posterior distribution that are not needed. Surprisingly in contrast, the Gibbs sampler explore non-useful sections and leaves the useful ones unexplored. Again, this is true no matter the number of iterations used in the adaptation, burn-in and sampling procedures\footnote{the author used the same settings as in the previous example.}. Moreover, the chains in figure \ref{fig:devil_CE_prior_jags} (appendix) seem ``healthy", ignoring the clear lack of exploration of the posterior, as in the previous example.

Third, we see that using regularizing priors reduced the number of \texttt{stan}'s divergent transitions from $150$ (in the previous example) to $50$. Although we still observe them in the steepest part of the geometry. Such information is not provided by \texttt{jags}.

Finally, we notice a mild improvement on the trace, tranks and ACF plots in figure \ref{fig:devil_prior}, compared to figure \ref{fig:devil_CE} in the previous example.
%
\begin{figure}[h] 
	\centering
	\begin{subfigure}
		\includegraphics[width=.7\linewidth]{2_trace_CE_priors}
	\end{subfigure}
	%
	\begin{subfigure}
		\includegraphics[width=.7\linewidth]{2_trank_CE_priors}
	\end{subfigure}
	%
	\begin{subfigure}
		\includegraphics[width=.7\linewidth]{2_acf_CE_priors}
	\end{subfigure}
	%
	\caption[The Devil's funnel. Centered Parametrization with prior information.]%
	{The Devil's funnel. Centered Parametrization with mildly informative priors. (Top) Trace plots for the iterations on three chains. (Middle) Trank plots for the same data. (Bottom) Auto-correlation Functions (ACF) plot for the iterations.}
	\label{fig:devil_prior}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Non-Centered Parametrization}

It would seem that, increasing the regularizing power of the priors is the answer to get rid of the sampling issues, raised by a complex posterior sampling geometry. However, there is a limit on the information a prior can contain, without imposing strong assumptions about the parameters in a model. Furthermore, sometimes researchers want the information on the data dominates the posterior parameter space. In those cases, imposing even mildly informative priors is a solution that is out of the picture.

In this context, \citet{Betancourt_et_al_2013} indicated that prior information can be included in the model, not only through the prior distributions, but also by encoding it in the model itself, taking advantage of the hierarchical structure explicitly, i.e. change the posterior sampling geometries. 

Under the Bayesian framework, a change in geometry consist on a re-parameterization of a model, that seeks to remove the dependence of parameters on other sampled parameters, therefore favoring the performance of the MCMC chains. This is what the literature has dubbed as the non-centered parametrization (NCP).
%
\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\linewidth]{3_funnel_NC}
	%
	\caption[Posterior sampling geometry. Non-Centered Parametrization.]%
	{Posterior sampling geometry. Non-Centered Parametrization. (A1, B1) geometry defined by the independent parameters $v$ and $z$. (A2, B2) Original sampling geometry defined by $v$ and $\theta$. (A1, A2) HMC algorithm (\texttt{stan}). (B1, B2) Metropolis/Gibbs sampler (\texttt{jags}). Blue points are accepted samples. Red points denote divergent transitions.}
	\label{fig:devil_NC_geom}
\end{figure}

In our case, changing the posterior sampling geometry means to modify equation (\ref{eq:devil}) in the following way:
%
\begin{equation} \label{eq:devil_NC}
	\begin{split}	
		v &\sim N(0, 3) \\
		z &\sim N(0, 1) \\
		\theta &= \text{exp}(v) \; z
	\end{split}
\end{equation}

\noindent notice $v$ has the original assumed variability, but now $\theta$ is defined in a way, that is no longer sample dependent on $v$, i.e. we no longer sample $\theta$ directly but $z$, and transform it back.

The motivation for this re-parametrization have seeds in the calculation of the standard score (z-sore). Notice that if $\theta \sim N(\mu_{\theta}, \sigma_{\theta})$ where $\sigma_{\theta} = \text{exp}(v)$, then $(\theta - \mu_{\theta})/\sigma_{\theta} = z$ and $z \sim N(0,1)$. Using this process in reverse, we notice $\theta = \mu_{\theta} + \sigma_{\theta} z = \text{exp}(v) \; z$ when $\mu_{\theta}=0$, then $\theta \sim N(0, \text{exp}(v))$. As the previous, there are transformation that can be done for other distributions, and they can even be extended to the multivariate normal case, through the use of the Cholesky decomposition \cite{McElreath_2020}.

For our current application however, figure \ref{fig:devil_NC_geom} show the posterior sampling geometry for the HMC and Gibbs sampler. Notice, under the re-parametrization, both algorithms manage to explore more successfully the posterior distribution, although HMC does it a bit better on the extremes of $v$. Moreover, HMC shows no divergent transitions, meaning the posterior is ``visited" without issues; as seen on figure \ref{fig:devil_NC}, where the chains show clear signs of stationarity, convergence and good mixing.

%
\begin{figure}[h]
	\centering
	\begin{subfigure}
		\includegraphics[width=1\linewidth]{3_trace_NC}
	\end{subfigure}
	%
	\begin{subfigure}
		\includegraphics[width=1\linewidth]{3_trank_NC}
	\end{subfigure}
	%
	\begin{subfigure}
		\includegraphics[width=1\linewidth]{3_acf_NC}
	\end{subfigure}
	%
	\caption[The Devil's funnel. Non-centered Parametrization.]%
	{The Devil's funnel. Non-centered Parametrization. (Top) Trace plots for the iterations on three chains. (Middle) Trank plots for the same data. (Bottom) Auto-correlation Functions (ACF) plots for the iterations.}
	\label{fig:devil_NC}
\end{figure}

Finally, \citet{Papaspiliopoulos_et_al_2007} indicated that the success of the NCP strategy is largely dependent on the specifics of the model, i.e. neither strategy is more ``optimal" than the other. The author pointed out that the natural CP showed better performance when conditional conjugacy was present, i.e. when the posterior distribution belonged to the same parametric family as the likelihood or prior distribution. On the other hand, the NCP worked as its complement, excelling when the previous requirement was not present. Therefore it makes sense that recent advancements on the topic are focused on producing sample mechanisms located in a continuous between CP and NCP, as greater performance improvements can be obtained by leveraging on the ``best of both worlds", e.g. Interleaved HMC (iHMC) or Variational Inference (VI) \cite{Gelfand_et_al_1995, Gelfand_et_al_1996, Papaspiliopoulos_et_al_2003, Papaspiliopoulos_et_al_2007, Gorinova_et_al_2019}.

Chapter \ref{chap:simulation} and \ref{chap:application} will show the application of non-centered parametrization in the context of an IRT model.
