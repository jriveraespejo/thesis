\chapter{Bayesian estimation} \label{chap:estimation}

The practical use of GLLAMM requires the estimation of the parameters associated with the items and the individuals' latent abilities, and these can be obtained within two frameworks: the classical (frequentist), and the bayesian. The current chapter center its attention on describing the bayesian framework using the Markov Chain Monte Carlo method (MCMC).

For a full development of GLLAMM under the classical (frequentist) estimation framework refer to \citet{Rabe_et_al_2004a, Rabe_et_al_2004b, Skrondal_et_al_2004a, Rabe_et_al_2012}.


\section{Benefits and shortcomings}

There are several reasons on why bayesian statistics is attractive to perform the estimation of the parameters of any model, and especially under the GLLAMM framework, among them:

\begin{enumerate}
	\item The bayesian estimates are at least as good as the classical (frequentist) estimates \cite{Baker_1998, Wollack_2002, Hsieh_2010}. 
	
	\item It is built on a simulation-based estimation method, therefore, it can handle all kinds of priors and data-generating processes \cite{Fox_2010}. This is especially useful with highly complex and over-parameterized models, where other methods are unfeasible or work poorly \cite{Baker_1998, Kim_1999}. 
	
	\item The model definitions are used to estimate the associated parameters, but they can also be used in a generative way, i.e. simulate observations, allowing us to test the ability of the method/data to recover the parameters of interest \cite{McElreath_2020}.
	
	\item It allow us to integrate prior beliefs or knowledge about the parameters of interest beyond the observed responses \cite{Fox_2010, Skrondal_et_al_2004a}. This is especially useful when we have issues of non-convergence or improper estimation of the parameters under the Maximum Likelihood methods (ML). Examples of these cases are:
	
	\begin{enumerate}
		\item Estimating abilities when individuals have null scores or aberrant response patterns, i.e. examinees that answered some relatively difficult and discriminating items correctly, while answering some of the easiest incorrectly. \cite{Hambleton_et_al_1991a, Azevedo_2003}.
		
		\item Estimating parameters that need to be confined to a permitted parameter space, e.g. the estimation of positive unique factors variances, where the opposite is known as ‘Heywood cases’ \cite{Martin_et_al_1975}
			
		\item Estimating parameters under a sparse data structure, where the asymptotic theory is unlikely to hold \cite{Fox_2010};
		
	\end{enumerate}
	
\end{enumerate}

\noindent Finally, in terms of shortcomings, the bayesian framework has the following inconveniences:

\begin{enumerate}	
	\item It exposes the user to arbitrary" decisions about the running of the chains, e.g. how many iterates does the chain need to achieve precise estimates?, what is the right size for the burn-in and warm-up phases? \cite{Skrondal_et_al_2004a}. 
	
	\item The user has many options to assess if the chain achieves stationarity, convergence or good mixing, and most of them are visual. This makes it hard to assess if the chain converges to a proper distribution \cite{Gelman_et_al_1996}.
	
	\item The procedure could make it hard to discover the lack of identification in parameters \cite{Skrondal_et_al_2004a}. Inadequate mixing of the chain could lead us to think that an unidentified parameter has been estimated with precision, when in fact, the parameter has a "flat" posterior \cite{Keane_1992}.

{\color{red}
	\item Without sufficient data the specification of noninformative priors leads to poor solutions, sometimes worse than with the classical methods. However, we can reach poor solutions even when we have enough data, an example for this is the estimation of the variance parameters in random effects models \cite{Skrondal_et_al_2004a}, but this applies also for the classical methods.
	
	\item the communication of the model can be daunting, difference between centered and non-centered versions \cite{McElreath_2020}.
	
	\item It takes too long 
}		
\end{enumerate}

{\color{red} 
(responses for shortcommings)

A popular approach to solve this issues is to use an arbitrary large number of iterates, or multiple chains with different initial states. However, Hamiltonian Monte Carlo methods (HMC) does not lean on this decision so much.

stationarity, convergence are more easy to assess visually (and have help of some statistics created, like Rhat). However, good mixing is much harder to assess visually. This is mildly solved with HMC and the different parametrizations (centered and non-centered).

In case of lack of identification, is better to regularize, which implies we are more skeptical of highly variant parameters \cite{McElreath_2020}.

set non-informative priors is a bad "policy" for the models because: .... \cite{McElreath_2020}

However, as it is described in section \ref{sect:comp_imp}, we will see that Hamiltonian Monte Carlo methods (HMC)

}
\section{Bayesian framework}

\subsection{Prior distribution}

\subsection{Initial start}

\subsection{Likelihood}

\subsection{Posterior distribution}


\section{Computational implementation} \label{sect:comp_imp}

{\color{red} (work in progress) \\
see 
- Gelman et al (2011) - Handbook of Markov Chain Monte Carlo
- McElreath (2020) - Statistical Rethinking

Rethinking: Warmup is not burn-in. Other MCMC algorithms and software often discuss burn-
in. With a sampling strategy like ordinary Metropolis, it is conventional and useful to trim off the
front of the chain, the “burn-in” phase. This is done because it is unlikely that the chain has reached
stationarity within the first few samples. Trimming off the front of the chain hopefully removes any
influence of which starting value you chose for a parameter. 156
But Stan’s sampling algorithms use a different approach. What Stan does during warmup is quite
different from what it does after warmup. The warmup samples are used to adapt sampling, to find
good values for the step size and the number of steps. Warmup samples are not representative of
the target posterior distribution, no matter how long warmup continues. They are not burning in,
but rather more like cycling the motor to heat things up and get ready for sampling. When real
sampling begins, the samples will be immediately from the target distribution, assuming adaptation
was successful.

}


The procedure will be with the aid of \texttt{Stan} \cite{Stan2020} and \texttt{R} \cite{R2015, RStan2020} to retrieve . \\




